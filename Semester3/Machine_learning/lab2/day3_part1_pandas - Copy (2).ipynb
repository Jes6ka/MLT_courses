{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239232 239232\n"
     ]
    }
   ],
   "source": [
    "import time, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from scipy.sparse import csr_matrix \t#Compressed Sparse Row matrix\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gc #Manually collect garbage\n",
    "\n",
    "phrasedict = pd.read_table(\"dictionary.txt\", names= [\"phrase\", \"phrase ids\"], sep=\"|\")\n",
    "sentilabels = pd.read_table(\"sentiment_labels.txt\", sep=\"|\") # names = ][phrase ids, sentiment values]\n",
    "\n",
    "print(len(phrasedict), len(sentilabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   phrase  phrase ids  length\n",
      "219092  to capitalize on Hopkins ' inclination to play...      216926     143\n",
      "181641  represents the worst kind of filmmaking , the ...      131377     138\n",
      "34627   It 's hard to imagine anybody ever being `` in...      224183     230\n",
      "106903  easily become a cold , calculated exercise in ...       78725     139\n",
      "55849   This is a movie that is what it is : a pleasan...      226649     115\n",
      "41775   Nicholson . Gone are the flamboyant mannerisms...      107992     226\n",
      "10198   , the film is so mired in juvenile and near-xe...      142483     170\n",
      "17599   Aggressive self-glorification and a manipulati...      143559     162\n",
      "103586  director Robert J . Siegel allows the characte...      118295     109\n",
      "191410  something that is so meditative and lyrical ab...      132968     228\n",
      "89570   blend politics and drama , an admirable ambiti...      155295     138\n",
      "93404   can get past the fantastical aspects and harsh...       15367     176\n",
      "90129   borrows a bit from the classics `` Wait Until ...      229442     143\n",
      "102856  develops into a gut-wrenching examination of t...      118175     108\n",
      "211276  the seemingly irreconcilable situation between...      136227     122\n",
      "55693   This fascinating look at Israel in ferment fee...      110438     173\n",
      "12040   ... Mafia , rap stars and hood rats butt their...       24120     158\n",
      "12163   ... ambition is in short supply in the cinema ...       24133     148\n",
      "18061   Although God Is Great addresses interesting ma...      182283     164\n",
      "138818  is like a year late for tapping into our reali...      232530     127\n",
      "161131  nice if the screenwriters had trusted audience...      206980     129\n",
      "205569  the film acquires an undeniable entertainment ...      236877     187\n",
      "152839  made fresh by an intelligent screenplay and gr...       86458     118\n",
      "111128  explores the seemingly irreconcilable situatio...      119566     133\n",
      "171103  only enhance the film 's otherworldly quality ...       35724     195\n",
      "13398   ? Yes . Did it move me to care about what happ...      142969     112\n",
      "111501  faced with the possibility that her life is me...      198429     163\n",
      "19091   An undeniably gorgeous , terminally smitten do...       63952     115\n",
      "23636   City by the Sea is the cinematic equivalent of...      144505     130\n",
      "186803  shame that Stealing Harvard is too busy gettin...      211362     122\n",
      "...                                                   ...         ...     ...\n",
      "9383    , one hopes Mr. Plympton will find room for on...      221485     110\n",
      "191086  some set of believable and comprehensible impu...      171609     128\n",
      "193038  started doing nothing but reacting to it - fee...       57312     207\n",
      "34499   It 's difficult to feel anything much while wa...      185104     126\n",
      "35814   It moves quickly , adroitly , and without fuss...       25797     150\n",
      "231120  what is missing from it all is a moral . What ...      177979     142\n",
      "46000   Russell lacks the visual panache , the comic t...      187039     111\n",
      "98526   contemplates a heartland so overwhelmed by its...      196161     116\n",
      "169467  on Hopkins ' inclination to play Hannibal Lect...      208386     129\n",
      "14715   A genuinely funny ensemble comedy that also as...      103623     160\n",
      "24863   De Niro looks bored , Murphy recycles Murphy ,...      144727     161\n",
      "11283   , you do n't want to be worrying about whether...      142666     126\n",
      "56122   This little film is so slovenly done , so prim...      189044     110\n",
      "211928  the story , like Ravel 's Bolero , builds to a...       96770     112\n",
      "204238  the daddy of all slashers arrives , still with...      173706     194\n",
      "99549   covers just about every cliche in the compendi...      196356     112\n",
      "33020   If you adored The Full Monty so resoundingly t...      184835     112\n",
      "1717    's a pretty good execution of a story that 's ...       60848     139\n",
      "18851   An incredibly low-rent Danish film , it brings...       24641     126\n",
      "185585  seen as just another teen movie , which means ...      211151     121\n",
      "198706  that 's amusing enough while you watch it , of...      213472     113\n",
      "33380   In capturing the understated comedic agony of ...      106692     132\n",
      "219107  to care about a young man whose only apparent ...      176024     124\n",
      "121001  gone into recruiting the right bands for the p...      200088     160\n",
      "35572   It is OK for a movie to be something of a sitc...       66726     137\n",
      "31479   Humorous and heartfelt , Douglas McGrath 's ve...      223717     116\n",
      "1231    's ( Ricci 's ) best work yet , this girl-woma...       23026     128\n",
      "168494  of two families in crisis -- and of two girls ...       89172     118\n",
      "200182  that it 's too close to real life to make sens...       94734     111\n",
      "32068   I found myself finally unmoved by this film , ...      146059     108\n",
      "\n",
      "[20000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "terms_duplicated = [word for line in phrasedict[\"phrase\"] for word in line.split(' ')]\n",
    "terms = set(terms_duplicated)\n",
    "\n",
    "phrasedict[\"length\"] = phrasedict[\"phrase\"].str.len()\n",
    "phrase_20000_ = phrasedict.sort_values(\"length\", ascending=False)[:20000]\n",
    "phrase_20000 = phrase_20000_.sample(frac=1)\n",
    "\n",
    "\n",
    "del [phrasedict, phrase_20000_] #memory release\n",
    "gc.collect()\n",
    "\n",
    "print(phrase_20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge table with score\n",
    "#merged_phrase_20000 = pd.concat(phrase_20000,sentilabels join=\"inner\")\n",
    "merged_phrase_20000 = phrase_20000.merge(sentilabels, how=\"inner\", on=\"phrase ids\")\n",
    "#print(merged_phrase_20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22348 20000 <class 'scipy.sparse.csc.csc_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# Extract tf-idf, will be normalized between 0-1\n",
    "columns = merged_phrase_20000[\"sentiment values\"]\n",
    "\n",
    "vectorizer   = TfidfVectorizer(norm = 'l2', vocabulary=terms) #len(terms) == 22348\n",
    "tfidf_matrix = vectorizer.fit_transform(merged_phrase_20000[\"phrase\"])\n",
    "tfidf_matrix = tfidf_matrix.T\n",
    "row, column  = tfidf_matrix.shape\n",
    "print(row, column, type(tfidf_matrix)) # 22348 terms, 20000 tweets(Documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_tfidf = pd.DataFrame(tfidf_matrix.toarray(), index=terms, columns=columns)\n",
    "del tfidf_matrix\n",
    "#pd_tfidf = pd.SparseDataFrame(tfidf_matrix, index=terms, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sentiment values</th>\n",
       "      <th>0.44444</th>\n",
       "      <th>0.22222</th>\n",
       "      <th>0.375</th>\n",
       "      <th>0.93056</th>\n",
       "      <th>0.73611</th>\n",
       "      <th>0.43056</th>\n",
       "      <th>0.27778</th>\n",
       "      <th>0.38889</th>\n",
       "      <th>0.75</th>\n",
       "      <th>0.875</th>\n",
       "      <th>...</th>\n",
       "      <th>0.70833</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.44444</th>\n",
       "      <th>0.47222</th>\n",
       "      <th>0.70833</th>\n",
       "      <th>0.81944</th>\n",
       "      <th>0.91667</th>\n",
       "      <th>0.52778</th>\n",
       "      <th>0.79167</th>\n",
       "      <th>0.40278</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>concocts</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entrepreneurial</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Twin</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ill-constructed</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "sentiment values  0.44444  0.22222  0.37500  0.93056  0.73611  0.43056  \\\n",
       "concocts              0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "Jean                  0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "entrepreneurial       0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "Twin                  0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "ill-constructed       0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "sentiment values  0.27778  0.38889  0.75000  0.87500   ...     0.70833  \\\n",
       "concocts              0.0      0.0      0.0      0.0   ...         0.0   \n",
       "Jean                  0.0      0.0      0.0      0.0   ...         0.0   \n",
       "entrepreneurial       0.0      0.0      0.0      0.0   ...         0.0   \n",
       "Twin                  0.0      0.0      0.0      0.0   ...         0.0   \n",
       "ill-constructed       0.0      0.0      0.0      0.0   ...         0.0   \n",
       "\n",
       "sentiment values  0.50000  0.44444  0.47222  0.70833  0.81944  0.91667  \\\n",
       "concocts              0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "Jean                  0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "entrepreneurial       0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "Twin                  0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "ill-constructed       0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "sentiment values  0.52778  0.79167  0.40278  \n",
       "concocts              0.0      0.0      0.0  \n",
       "Jean                  0.0      0.0      0.0  \n",
       "entrepreneurial       0.0      0.0      0.0  \n",
       "Twin                  0.0      0.0      0.0  \n",
       "ill-constructed       0.0      0.0      0.0  \n",
       "\n",
       "[5 rows x 20000 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concocts            0\n",
      "Jean                0\n",
      "entrepreneurial     0\n",
      "Twin                0\n",
      "ill-constructed     0\n",
      "published           0\n",
      "1970                0\n",
      "menacing            0\n",
      "spare               0\n",
      "underestimate       0\n",
      "well-meaning        0\n",
      "islanders           0\n",
      "styled              0\n",
      "terrorizing         0\n",
      "genres              0\n",
      "empathize           0\n",
      "Hjejle              0\n",
      "indoctrinated       0\n",
      "tight               0\n",
      "Who                 0\n",
      "clocked             0\n",
      "non-techies         0\n",
      "unabashedly         0\n",
      "filmgoers           0\n",
      "heavy-handed        0\n",
      "upping              0\n",
      "mystique            0\n",
      "Utter               0\n",
      "preordained         0\n",
      "evolves             0\n",
      "                   ..\n",
      "forces             10\n",
      "Murder              0\n",
      "motorcycles         0\n",
      "anticipated         6\n",
      "selfish             0\n",
      "Standing            9\n",
      "donde               1\n",
      "Rosemary           18\n",
      "stereotypes         2\n",
      "frequent            2\n",
      "ruffle              1\n",
      "jump               10\n",
      "Book                0\n",
      "whiplash            2\n",
      "dorkier             2\n",
      "fifteen-minute      0\n",
      "Rowling             0\n",
      "toothless           2\n",
      "kegger              0\n",
      "e                   0\n",
      "laughter           14\n",
      "mercy               4\n",
      "half-step          13\n",
      "collective          0\n",
      "trial               3\n",
      "Again              59\n",
      "ser                 1\n",
      "soaringly           2\n",
      "bullet              0\n",
      "praises             2\n",
      "Length: 22348, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#pd_tfidf.to_csv(\"tf-idf_sungmin.csv\", sep=\",\", encoding=\"utf-8\") # about 1.7GB\n",
    "#if any((0,0,0,0)) : print(1) >> print nothing\n",
    "#if any((0,0,0,1)) : print(1) >> print 1\n",
    "\n",
    "#drop_list = list()\n",
    "\n",
    "#for index, row in pd_tfidf.iterrows():\n",
    "#    if any(row.values): drop_list.append(index)\n",
    "#     #else : print(\"find some values\")\n",
    "# print(drop_list)\n",
    "\n",
    "#updated_tfidf = pd_tfidf[(pd_tfidf.T != 0).any()]\n",
    "nonzero_tfidf = (pd_tfidf!=0).astype(int).sum(axis=1)\n",
    "\n",
    "\n",
    "print(nonzero_tfidf) # 22348 rows × 20000 columns => 13185 rows × 20000 columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nonzero_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c0d720d55748>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#print(type(nonzero_tfidf), nonzero_tfidf.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mFEATURE_NUMBER\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msorted_nonzero_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnonzero_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mFEATURE_NUMBER\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_nonzero_tfidf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfeatures_N\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted_nonzero_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nonzero_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "#print(type(nonzero_tfidf), nonzero_tfidf.shape)\n",
    "FEATURE_NUMBER = 500\n",
    "sorted_nonzero_tfidf = pd.DataFrame(nonzero_tfidf.sort_values(ascending=False)[:FEATURE_NUMBER])\n",
    "print(sorted_nonzero_tfidf)\n",
    "features_N = sorted_nonzero_tfidf.index\n",
    "try : del [nonzero_tfidf]\n",
    "except : pass\n",
    "gc.collect()\n",
    "\n",
    "print(features_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-dd69bbd30a88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#tfidf.drop(tfidf.columns[0], axis=1, inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures_N\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#print(tfidf)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "#tfidf = pd.merge(sorted_nonzero_tfidf, pd_tfidf, left_index=True, right_index=True)\n",
    "#tfidf = pd.concat([sorted_nonzero_tfidf, pd_tfidf], axis=1)\n",
    "#or pd.merge(df1, df2, left_index=True, right_index=True)\n",
    "#or df1.join(df2) #by default there is left join:\n",
    "#or pd.concat([df1, df2], axis=1) #by default there is outer join\n",
    "\n",
    "\n",
    "#delete last coulmn : it was count of tfidf scores from above.\n",
    "#tfidf.drop(tfidf.columns[len(tfidf.columns)-1], axis=1, inplace=True)\n",
    "#tfidf.drop(tfidf.columns[0], axis=1, inplace=True)\n",
    "\n",
    "tfidf = pd_tfidf.loc[features_N]\n",
    "\n",
    "#print(tfidf)\n",
    "assert [i for i in tfidf.columns if isinstance(i, str)] == []\n",
    "#tfidf.drop(tfidf.columns[\"0.0_y\"], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf, somewhere is not 0 but value :  murders 0.102462656456\n"
     ]
    }
   ],
   "source": [
    "#for test if it has all zero value.\n",
    "try : del [pd_tfidf] #memory release\n",
    "except : pass\n",
    "gc.collect()\n",
    "\n",
    "for i in tfidf.iloc[0,:]: # term \"great\" has more.\n",
    "    if i!=0:\n",
    "        print(\"tf-idf, somewhere is not 0 but value : \", tfidf.index[0], i)\n",
    "        break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sentiment values</th>\n",
       "      <th>0.44444</th>\n",
       "      <th>0.22222</th>\n",
       "      <th>0.375</th>\n",
       "      <th>0.93056</th>\n",
       "      <th>0.73611</th>\n",
       "      <th>0.43056</th>\n",
       "      <th>0.27778</th>\n",
       "      <th>0.38889</th>\n",
       "      <th>0.75</th>\n",
       "      <th>0.875</th>\n",
       "      <th>...</th>\n",
       "      <th>0.70833</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.44444</th>\n",
       "      <th>0.47222</th>\n",
       "      <th>0.70833</th>\n",
       "      <th>0.81944</th>\n",
       "      <th>0.91667</th>\n",
       "      <th>0.52778</th>\n",
       "      <th>0.79167</th>\n",
       "      <th>0.40278</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>murders</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102463</td>\n",
       "      <td>0.106051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074050</td>\n",
       "      <td>0.142135</td>\n",
       "      <td>0.052635</td>\n",
       "      <td>0.060462</td>\n",
       "      <td>0.042652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047635</td>\n",
       "      <td>0.059666</td>\n",
       "      <td>0.239772</td>\n",
       "      <td>0.171837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fork</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116821</td>\n",
       "      <td>0.040304</td>\n",
       "      <td>0.057683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042213</td>\n",
       "      <td>0.054017</td>\n",
       "      <td>0.120022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109348</td>\n",
       "      <td>0.065305</td>\n",
       "      <td>0.154359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zips</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086662</td>\n",
       "      <td>0.055448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055747</td>\n",
       "      <td>0.069828</td>\n",
       "      <td>0.112244</td>\n",
       "      <td>0.067035</td>\n",
       "      <td>0.079223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beanie</th>\n",
       "      <td>0.200049</td>\n",
       "      <td>0.069078</td>\n",
       "      <td>0.190658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163049</td>\n",
       "      <td>0.057510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173164</td>\n",
       "      <td>0.079081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Episode</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093431</td>\n",
       "      <td>0.057726</td>\n",
       "      <td>0.073868</td>\n",
       "      <td>0.082064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099658</td>\n",
       "      <td>0.074267</td>\n",
       "      <td>0.093025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200231</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "sentiment values   0.44444   0.22222   0.37500   0.93056   0.73611   0.43056  \\\n",
       "murders           0.000000  0.102463  0.106051  0.000000  0.000000  0.074050   \n",
       "Fork              0.000000  0.116821  0.040304  0.057683  0.000000  0.042213   \n",
       "zips              0.000000  0.059957  0.000000  0.059210  0.000000  0.086662   \n",
       "beanie            0.200049  0.069078  0.190658  0.000000  0.080801  0.000000   \n",
       "Episode           0.000000  0.079875  0.000000  0.000000  0.093431  0.057726   \n",
       "\n",
       "sentiment values   0.27778   0.38889   0.75000   0.87500    ...      0.70833  \\\n",
       "murders           0.142135  0.052635  0.060462  0.042652    ...     0.000000   \n",
       "Fork              0.054017  0.120022  0.000000  0.145887    ...     0.072877   \n",
       "zips              0.055448  0.000000  0.000000  0.049917    ...     0.000000   \n",
       "beanie            0.063882  0.000000  0.163049  0.057510    ...     0.000000   \n",
       "Episode           0.073868  0.082064  0.000000  0.132999    ...     0.099658   \n",
       "\n",
       "sentiment values   0.50000   0.44444   0.47222   0.70833   0.81944   0.91667  \\\n",
       "murders           0.047635  0.059666  0.239772  0.171837  0.000000  0.052894   \n",
       "Fork              0.000000  0.000000  0.109348  0.065305  0.154359  0.000000   \n",
       "zips              0.055747  0.069828  0.112244  0.067035  0.079223  0.000000   \n",
       "beanie            0.000000  0.080450  0.000000  0.077232  0.000000  0.000000   \n",
       "Episode           0.074267  0.093025  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "sentiment values   0.52778   0.79167   0.40278  \n",
       "murders           0.000000  0.000000  0.000000  \n",
       "Fork              0.113634  0.000000  0.066869  \n",
       "zips              0.116643  0.000000  0.000000  \n",
       "beanie            0.000000  0.173164  0.079081  \n",
       "Episode           0.000000  0.200231  0.000000  \n",
       "\n",
       "[5 rows x 20000 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "tfidf = pd.DataFrame(ss.fit_transform(tfidf), index=tfidf.index, columns = tfidf.columns)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sentiment values</th>\n",
       "      <th>0.44444</th>\n",
       "      <th>0.22222</th>\n",
       "      <th>0.375</th>\n",
       "      <th>0.93056</th>\n",
       "      <th>0.73611</th>\n",
       "      <th>0.43056</th>\n",
       "      <th>0.27778</th>\n",
       "      <th>0.38889</th>\n",
       "      <th>0.75</th>\n",
       "      <th>0.875</th>\n",
       "      <th>...</th>\n",
       "      <th>0.70833</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.44444</th>\n",
       "      <th>0.47222</th>\n",
       "      <th>0.70833</th>\n",
       "      <th>0.81944</th>\n",
       "      <th>0.91667</th>\n",
       "      <th>0.52778</th>\n",
       "      <th>0.79167</th>\n",
       "      <th>0.40278</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>murders</th>\n",
       "      <td>-0.132271</td>\n",
       "      <td>4.095418</td>\n",
       "      <td>3.508980</td>\n",
       "      <td>-0.115273</td>\n",
       "      <td>-0.122867</td>\n",
       "      <td>3.603677</td>\n",
       "      <td>5.607905</td>\n",
       "      <td>2.604622</td>\n",
       "      <td>2.106192</td>\n",
       "      <td>1.584598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153923</td>\n",
       "      <td>2.636377</td>\n",
       "      <td>1.459080</td>\n",
       "      <td>7.725541</td>\n",
       "      <td>5.787911</td>\n",
       "      <td>-0.103191</td>\n",
       "      <td>1.644815</td>\n",
       "      <td>-0.129532</td>\n",
       "      <td>-0.158405</td>\n",
       "      <td>-0.138936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fork</th>\n",
       "      <td>-0.132271</td>\n",
       "      <td>4.686995</td>\n",
       "      <td>1.224493</td>\n",
       "      <td>2.556131</td>\n",
       "      <td>-0.122867</td>\n",
       "      <td>2.002110</td>\n",
       "      <td>2.016743</td>\n",
       "      <td>6.098329</td>\n",
       "      <td>-0.129487</td>\n",
       "      <td>5.831080</td>\n",
       "      <td>...</td>\n",
       "      <td>1.931197</td>\n",
       "      <td>-0.131485</td>\n",
       "      <td>-0.192112</td>\n",
       "      <td>3.432014</td>\n",
       "      <td>2.090826</td>\n",
       "      <td>5.491158</td>\n",
       "      <td>-0.162513</td>\n",
       "      <td>4.520671</td>\n",
       "      <td>-0.158405</td>\n",
       "      <td>2.578604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zips</th>\n",
       "      <td>-0.132271</td>\n",
       "      <td>2.344078</td>\n",
       "      <td>-0.175930</td>\n",
       "      <td>2.626864</td>\n",
       "      <td>-0.122867</td>\n",
       "      <td>4.238125</td>\n",
       "      <td>2.075032</td>\n",
       "      <td>-0.124293</td>\n",
       "      <td>-0.129487</td>\n",
       "      <td>1.883412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153923</td>\n",
       "      <td>3.107788</td>\n",
       "      <td>1.740304</td>\n",
       "      <td>3.527327</td>\n",
       "      <td>2.150835</td>\n",
       "      <td>2.768047</td>\n",
       "      <td>-0.162513</td>\n",
       "      <td>4.643799</td>\n",
       "      <td>-0.158405</td>\n",
       "      <td>-0.138936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beanie</th>\n",
       "      <td>8.117193</td>\n",
       "      <td>2.719876</td>\n",
       "      <td>6.448788</td>\n",
       "      <td>-0.115273</td>\n",
       "      <td>3.335907</td>\n",
       "      <td>-0.121451</td>\n",
       "      <td>2.418787</td>\n",
       "      <td>-0.124293</td>\n",
       "      <td>5.899456</td>\n",
       "      <td>2.195762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153923</td>\n",
       "      <td>-0.131485</td>\n",
       "      <td>2.034268</td>\n",
       "      <td>-0.167713</td>\n",
       "      <td>2.504728</td>\n",
       "      <td>-0.103191</td>\n",
       "      <td>-0.162513</td>\n",
       "      <td>-0.129532</td>\n",
       "      <td>4.837859</td>\n",
       "      <td>3.074904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Episode</th>\n",
       "      <td>-0.132271</td>\n",
       "      <td>3.164752</td>\n",
       "      <td>-0.175930</td>\n",
       "      <td>-0.115273</td>\n",
       "      <td>3.876539</td>\n",
       "      <td>2.782480</td>\n",
       "      <td>2.825730</td>\n",
       "      <td>4.130369</td>\n",
       "      <td>-0.129487</td>\n",
       "      <td>5.300924</td>\n",
       "      <td>...</td>\n",
       "      <td>2.697442</td>\n",
       "      <td>4.183899</td>\n",
       "      <td>2.382268</td>\n",
       "      <td>-0.167713</td>\n",
       "      <td>-0.175538</td>\n",
       "      <td>-0.103191</td>\n",
       "      <td>-0.162513</td>\n",
       "      <td>-0.129532</td>\n",
       "      <td>5.618813</td>\n",
       "      <td>-0.138936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "sentiment values   0.44444   0.22222   0.37500   0.93056   0.73611   0.43056  \\\n",
       "murders          -0.132271  4.095418  3.508980 -0.115273 -0.122867  3.603677   \n",
       "Fork             -0.132271  4.686995  1.224493  2.556131 -0.122867  2.002110   \n",
       "zips             -0.132271  2.344078 -0.175930  2.626864 -0.122867  4.238125   \n",
       "beanie            8.117193  2.719876  6.448788 -0.115273  3.335907 -0.121451   \n",
       "Episode          -0.132271  3.164752 -0.175930 -0.115273  3.876539  2.782480   \n",
       "\n",
       "sentiment values   0.27778   0.38889   0.75000   0.87500    ...      0.70833  \\\n",
       "murders           5.607905  2.604622  2.106192  1.584598    ...    -0.153923   \n",
       "Fork              2.016743  6.098329 -0.129487  5.831080    ...     1.931197   \n",
       "zips              2.075032 -0.124293 -0.129487  1.883412    ...    -0.153923   \n",
       "beanie            2.418787 -0.124293  5.899456  2.195762    ...    -0.153923   \n",
       "Episode           2.825730  4.130369 -0.129487  5.300924    ...     2.697442   \n",
       "\n",
       "sentiment values   0.50000   0.44444   0.47222   0.70833   0.81944   0.91667  \\\n",
       "murders           2.636377  1.459080  7.725541  5.787911 -0.103191  1.644815   \n",
       "Fork             -0.131485 -0.192112  3.432014  2.090826  5.491158 -0.162513   \n",
       "zips              3.107788  1.740304  3.527327  2.150835  2.768047 -0.162513   \n",
       "beanie           -0.131485  2.034268 -0.167713  2.504728 -0.103191 -0.162513   \n",
       "Episode           4.183899  2.382268 -0.167713 -0.175538 -0.103191 -0.162513   \n",
       "\n",
       "sentiment values   0.52778   0.79167   0.40278  \n",
       "murders          -0.129532 -0.158405 -0.138936  \n",
       "Fork              4.520671 -0.158405  2.578604  \n",
       "zips              4.643799 -0.158405 -0.138936  \n",
       "beanie           -0.129532  4.837859  3.074904  \n",
       "Episode          -0.129532  5.618813 -0.138936  \n",
       "\n",
       "[5 rows x 20000 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 20000\n",
      "phrases_train, test :  (16000,) (4000,)\n",
      "tfidf_train, test :  (16000, 500) (4000, 500)\n"
     ]
    }
   ],
   "source": [
    "#terms are features, sentiment values are extract from phrase_20000\n",
    "row, column = tfidf.shape\n",
    "print(row, column)\n",
    "test_percentage = 20\n",
    "boundary = int(column*(1-test_percentage/100)) #16000\n",
    "\n",
    "#change to np.array, (16000,), (4000,) \n",
    "phrases_train  = np.array(tfidf.columns[:boundary])\n",
    "phrases_test   = np.array(tfidf.columns[boundary:])\n",
    "\n",
    "print(\"phrases_train, test : \", phrases_train.shape, phrases_test.shape)\n",
    "\n",
    "\n",
    "tfidf_train_    = tfidf.iloc[:,:boundary]\n",
    "tfidf_test_    = tfidf.iloc[:,boundary:]\n",
    "\n",
    "tfidf_train = tfidf_train_.T\n",
    "tfidf_test  = tfidf_test_.T\n",
    "\n",
    "del [tfidf_train_, tfidf_test_] #memory release\n",
    "gc.collect()\n",
    "\n",
    "print(\"tfidf_train, test : \", tfidf_train.shape, tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][ 0.875    0.19444  0.45833  0.81944  0.875    0.90278  0.45833  0.33333\n",
      "  0.77778  0.30556  0.75     0.70833  0.47222  0.61111  0.47222  0.75\n",
      "  0.38889  0.51389  0.27778  0.61111]\n",
      "time cose : 12.235 s\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "clf = SVR(kernel=\"rbf\", degree=3, gamma=\"auto\", coef0=0.0, tol=0.001, C=1.0, \n",
    "          epsilon=0.1, shrinking=True, cache_size=200, verbose=True, max_iter=-1)\n",
    "clf.fit(tfidf_train, phrases_train)\n",
    "\n",
    "print(phrases_train[:20])\n",
    "print(\"time cose : %.3f s\" %(time.time()-time_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][ 0.56944  0.36111  0.19444  0.125    0.33333  0.88889  0.       0.83333\n",
      "  0.76389  0.54167  0.16667  0.5      0.20833  0.18056  0.88889  0.43056\n",
      "  0.47222  0.70833  0.68056  0.33333]\n",
      "time cose : 333.613 s\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "clf = SVR(kernel=\"rbf\", degree=3, gamma=\"auto\", coef0=0.0, tol=0.001, C=1.0, \n",
    "          epsilon=0.1, shrinking=True, cache_size=200, verbose=True, max_iter=-1)\n",
    "clf.fit(tfidf_train, phrases_train)\n",
    "\n",
    "print(phrases_train[:20])\n",
    "print(\"time cose : %.3f s\" %(time.time()-time_start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF prediction is :  64.757%   \n",
      "time cose : 19.219 s\n"
     ]
    }
   ],
   "source": [
    "#what I have to do is,\n",
    "#predict(X=[some_Values])\n",
    "#score(X, y) y is true for X.\n",
    "#from sklearn.metrics import accuracy_score\n",
    "time_start  = time.time()\n",
    "#rbf_predict = clf.predict(tfidf_test)\n",
    "rbf_score = clf.score(tfidf_test, phrases_test)\n",
    "print(\"RBF prediction is :  %.3f%% \" % (rbf_score*100), \" \\ntime cose : %.3f s\" %(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF prediction is :  60.473%   \n",
      "time cose : 2.909 s\n"
     ]
    }
   ],
   "source": [
    "#what I have to do is,\n",
    "#predict(X=[some_Values])\n",
    "#score(X, y) y is true for X.\n",
    "#from sklearn.metrics import accuracy_score\n",
    "time_start  = time.time()\n",
    "#rbf_predict = clf.predict(tfidf_test)\n",
    "rbf_score = clf.score(tfidf_test, phrases_test)\n",
    "print(\"RBF prediction is :  %.3f%% \" % (rbf_score*100), \" \\ntime cose : %.3f s\" %(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]time cose : 19.154 s\n"
     ]
    }
   ],
   "source": [
    "#del [clf] #memory release\n",
    "gc.collect()\n",
    "\n",
    "time_start = time.time()\n",
    "clf2 = SVR(kernel=\"linear\", degree=3, gamma=\"auto\", coef0=0.0, tol=0.001, C=1.0, \n",
    "          epsilon=0.1, shrinking=True, cache_size=200, verbose=True, max_iter=-1)\n",
    "clf2.fit(tfidf_train, phrases_train)\n",
    "print(\"time cose : %.3f s\" %(time.time()-time_start))\n",
    "#took about 65minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear prediction is :  27.984%   \n",
      "time cose : 2.609 s\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "linear_score = clf2.score(tfidf_test, phrases_test)\n",
    "print(\"Linear prediction is :  %.3f%% \" % (linear_score*100), \" \\ntime cose : %.3f s\" %(time.time()-time_start))\n",
    "#score : 0.2588100489097338 for 500 terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='poly', max_iter=-1, shrinking=True, tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = SVR(kernel=\"poly\", degree=3, gamma=\"auto\", coef0=0.0, tol=0.001, C=1.0, \n",
    "          epsilon=0.1, shrinking=True, cache_size=200, verbose=True, max_iter=-1)\n",
    "clf3.fit(tfidf_train, phrases_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear prediction is :  55.959%   \n",
      "time cose : 2.664 s\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "poly_score = clf3.score(tfidf_test, phrases_test)\n",
    "print(\"Linear prediction is :  %.3f%% \" % (poly_score*100), \" \\ntime cose : %.3f s\" %(time.time()-time_start))\n",
    "#score : 0.2588100489097338 for 500 terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "Best estimator found by grid search:\n",
      "SVR(C=100, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "#param_grid = {'C': [0.01, 0.1, 1, 10, 100], 'kernel': ['rbf', 'linear']}\n",
    "param_grid = {'C': [0.01, 1, 100], 'kernel': ['rbf', 'linear']}\n",
    "\n",
    "clf4 = GridSearchCV(SVR(), param_grid)\n",
    "clf4 = clf4.fit(tfidf_train, phrases_train)\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf4.best_estimator_)\n",
    "#it took more than 30min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27422574329624794"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4.score(tfidf_test,phrases_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cose : 25.680 s\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "from sklearn.svm import LinearSVR\n",
    "clf5 = LinearSVR()\n",
    "clf5.fit(tfidf_train, phrases_train)\n",
    "print(\"time cose : %.3f s\" %(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model data can explain data with :  -36.057%   \n",
      "time cose : 0.074 s\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "linear_score = clf5.score(tfidf_test, phrases_test)\n",
    "print(\"Linear model data can explain data with :  %.3f%% \" % (linear_score*100), \" \\ntime cose : %.3f s\" %(time.time()-time_start))\n",
    "#score : 0.2588100489097338 for 500 terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the classifier to the training set\n",
      "Best estimator found by grid search:\n",
      "LinearSVR(C=0.01, dual=True, epsilon=0.0, fit_intercept=True,\n",
      "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
      "     random_state=42, tol=0.0001, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "print(\"Fitting the classifier to the training set\")\n",
    "#param_grid = {'C': [0.01, 0.1, 1, 10, 100], 'kernel': ['rbf', 'linear']}\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "clf6 = GridSearchCV(LinearSVR(random_state=42), param_grid)\n",
    "clf6 = clf6.fit(tfidf_train, phrases_train)\n",
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf6.best_estimator_)\n",
    "#it took more than 30min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model data can explain data with :  23.274% \n"
     ]
    }
   ],
   "source": [
    "linear_score = clf6.score(tfidf_test, phrases_test)\n",
    "print(\"Linear model data can explain data with :  %.3f%% \" % (linear_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "from sklearn.externals import joblib\n",
    ">>> joblib.dump(clf, 'filename.pkl') \n",
    "\n",
    "#load model\n",
    "import pickle\n",
    "s = pickle.dumps(clf)\n",
    "clf2 = pickle.loads(s)\n",
    "clf2.predict(X[0:1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
