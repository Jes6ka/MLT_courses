{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.enable()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa, glob, os\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(\"wav\\*.wav\")\n",
    "TEST_PERCENTAGE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_data(file_name):\n",
    "    y, sr = librosa.load(file_name, mono=\"mono\")\n",
    "    S, phase = librosa.magphase(librosa.stft(y))\n",
    "    return (y, sr, S)\n",
    "\n",
    "def get_features(y, sr, S):\n",
    "    ms    = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
    "    mfcc  = librosa.feature.mfcc(S=librosa.power_to_db(ms), n_mfcc=20)\n",
    "\n",
    "    sp_cent =librosa.feature.spectral_centroid(y=y, sr=sr) \n",
    "\n",
    "    sp_band = librosa.feature.spectral_bandwidth(S=S)\n",
    "\n",
    "    _S = np.abs(librosa.stft(y))\n",
    "    sp_contra = librosa.feature.spectral_contrast(S=_S, sr=sr)\n",
    "\n",
    "\n",
    "    sp_roll  = librosa.feature.spectral_rolloff(S=S, sr=sr)# , roll_percent=0.95)\n",
    "\n",
    "    rmse = librosa.feature.rmse(S=S)\n",
    "\n",
    "    chroma_cens = librosa.feature.chroma_cens(y=y, sr=sr)\n",
    "\n",
    "    zero_rate = librosa.feature.zero_crossing_rate(y)\n",
    "\n",
    "    hop_length = 512\n",
    "    oenv = librosa.onset.onset_strength(y=y, sr=sr, hop_length=hop_length)\n",
    "    tempogram = librosa.feature.tempogram(onset_envelope=oenv, sr=sr, win_length=20, hop_length=hop_length)\n",
    "\n",
    "\n",
    "    return np.array([mfcc,sp_cent,sp_band,sp_contra,sp_roll,rmse,chroma_cens,zero_rate, tempogram])\n",
    "\n",
    "def get_3features(y, sr, S):\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    mfcc = np.mean(mfcc.T, axis=0)\n",
    "    \n",
    "    chroma_cens = librosa.feature.chroma_cens(y=y, sr=sr, n_chroma=20)\n",
    "    chroma_cens = np.mean(chroma_cens.T, axis=0)\n",
    "    \n",
    "    hop_length = 512\n",
    "    oenv = librosa.onset.onset_strength(y=y, sr=sr, hop_length=hop_length)\n",
    "    tempogram = librosa.feature.tempogram(onset_envelope=oenv, sr=sr, win_length=20, hop_length=hop_length)\n",
    "    tempogram = np.mean(tempogram.T, axis=0)\n",
    "    \n",
    "    return  np.array([[q,w,e] for q,w,e in zip(mfcc, chroma_cens, tempogram)])\n",
    "\n",
    "#\treturn np.array([mfcc,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatted_resized(messed_matrix):\n",
    "    flatted_matrix = [messed_matrix[i].reshape([1, len(messed_matrix[i])*len(messed_matrix[i][0])]) for i in range(len(messed_matrix))]\n",
    "    flatted_resized_features = [0]*len(flatted_matrix)\n",
    "\n",
    "    for i in range(len(flatted_matrix)):\n",
    "        k = 0\n",
    "        while( (flatted_matrix[i].shape[1]-k) %10 != 0):\n",
    "            k+=1\n",
    "        flatted_resized_features[i] = flatted_matrix[i][0][k:]\n",
    "\n",
    "    return flatted_resized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split2fragment(flatted_resized_features):\n",
    "    temp = []\n",
    "    for whole_frame in flatted_resized_features:\n",
    "        tp = []\n",
    "        interval = int(len(whole_frame)/10)\n",
    "        #print(interval)\n",
    "        for i in range(0, len(whole_frame), interval):\n",
    "            try : tp.append(whole_frame[i:i+interval])\n",
    "            except : pass\n",
    "        temp.append(tp)\n",
    "\n",
    "#     for i in range(len(temp)):\n",
    "#         assert len(temp[2])==10\n",
    "\n",
    "    #len(temp[0][0]), len(temp[1][0]), len(temp[2][0])\n",
    "\n",
    "#frame1.squeeze()\n",
    "#frame1 = np.hstack(frame1) #stack the arrays in sequence horizontally\n",
    "    \n",
    "    one_file = list()\n",
    "    for n in range(10):\n",
    "        extract_features = np.array([temp[i][n] for i in range(len(temp))])\n",
    "        flatten_features = np.hstack(extract_features)\n",
    "        one_file.append(flatten_features)\n",
    "    \n",
    "    return np.array(one_file)\n",
    "    #one_file = np.array([one_file])\n",
    "    \n",
    "#[len(frame1[i]) for i in range(len(frame1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428, 107)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_list = file_list[:int(len(file_list)*(1-TEST_PERCENTAGE))]\n",
    "test_file_list  = file_list[int(len(file_list)*(1-TEST_PERCENTAGE)):]\n",
    "len(train_file_list), len(test_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n",
      "one file success\n"
     ]
    }
   ],
   "source": [
    "train_y_sr_list     = list()\n",
    "test_y_sr_list     = list()\n",
    "\n",
    "for file_name in train_file_list:\n",
    "    y, sr, S                 = load_audio_data(file_name)\n",
    "    onefile_data           = get_3features(y, sr, S)\n",
    "    #feature_values           = get_features(y, sr, S)\n",
    "    #flatted_resized_features = flatted_resized(feature_values)\n",
    "    #onefile_data             = split2fragment(flatted_resized_features)\n",
    "\n",
    "    train_y_sr_list.append(onefile_data)\n",
    "    print(\"one file success\")\n",
    "\n",
    "for file_name in test_file_list:\n",
    "    y, sr, S                 = load_audio_data(file_name)\n",
    "    onefile_data           = get_3features(y, sr, S)\n",
    "    #feature_values           = get_features(y, sr, S)\n",
    "    #flatted_resized_features = flatted_resized(feature_values)\n",
    "    #onefile_data             = split2fragment(flatted_resized_features)\n",
    "    \n",
    "    test_y_sr_list.append(onefile_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428, 20, 3, 3)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y_sr_list), len(train_y_sr_list[0]), len(train_y_sr_list[0][1]), len(train_y_sr_list[3][1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 4, 6, 2, 4, 5, 6, 6, 0, 2, 3, 4, 5, 6, 0, 2, 4, 5, 6, 6, 2, 2, 3,\n",
       "        4, 6, 2, 3, 4, 5, 6, 6, 0, 3, 4, 5, 6, 4, 5, 6, 3, 4, 5, 6, 0, 1, 4,\n",
       "        4, 6, 6, 0, 2, 3, 4, 6, 6, 0, 0, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 2, 3,\n",
       "        4, 5, 6, 2, 3, 4, 5, 5, 6, 0, 2, 2, 3, 4, 6, 2, 3, 4, 5, 6, 2, 3, 4,\n",
       "        5, 6, 0, 2, 3, 4, 5, 6, 6, 0, 2, 3, 4, 5, 6, 1, 2, 4, 6, 1, 1, 3, 6,\n",
       "        2, 3, 4, 6, 1, 3, 4, 5, 6, 6, 1, 4, 5, 6, 6, 1, 4, 6, 4, 5, 6, 6, 1,\n",
       "        2, 2, 3, 4, 5, 6, 1, 4, 6, 0, 4, 6, 0, 4, 6, 0, 2, 3, 4, 6, 2, 4, 6,\n",
       "        6, 0, 3, 5, 6, 0, 0, 3, 5, 6, 0, 1, 2, 3, 0, 3, 4, 6, 3, 5, 6, 0, 3,\n",
       "        6, 2, 3, 6, 0, 0, 3, 4, 6, 1, 2, 3, 4, 5, 6, 0, 2, 4, 6, 0, 2, 2, 3,\n",
       "        4, 5, 6, 0, 3, 5, 6, 0, 1, 2, 3, 4, 6, 0, 2, 4, 5, 6, 2, 3, 4, 5, 6,\n",
       "        6, 0, 2, 3, 4, 5, 6, 0, 0, 3, 4, 5, 6, 2, 3, 4, 6, 0, 1, 4, 6, 6, 6,\n",
       "        0, 3, 4, 5, 6, 0, 3, 6, 5, 6, 0, 1, 2, 4, 6, 6, 6, 3, 5, 0, 5, 6, 0,\n",
       "        3, 6, 0, 1, 1, 2, 3, 4, 6, 0, 1, 2, 3, 4, 5, 6, 0, 2, 3, 5, 6, 0, 1,\n",
       "        3, 4, 5, 6, 6, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 6, 2, 3, 4, 6, 0, 1, 2,\n",
       "        3, 4, 5, 6, 0, 1, 2, 2, 3, 4, 6, 1, 2, 3, 4, 6, 6, 0, 0, 1, 4, 6, 6,\n",
       "        0, 1, 2, 3, 4, 5, 6, 6, 0, 1, 3, 5, 5, 6, 6, 0, 0, 2, 2, 3, 4, 5, 5,\n",
       "        6, 6, 0, 1, 2, 3, 3, 4, 5, 6, 0, 1, 2, 2, 4, 6, 0, 2, 4, 5, 6, 6, 0,\n",
       "        1, 3, 5, 6, 0, 1, 2, 3, 5, 6, 6, 0, 1, 3, 4, 5, 6, 1, 2, 3, 4, 6, 0,\n",
       "        1, 3, 4, 5, 6, 6, 0, 0, 2, 4, 6, 6, 1, 2, 3, 4, 6, 0, 1, 2, 2, 3, 4,\n",
       "        1, 3, 4, 6, 0, 3, 4, 5, 6, 6, 0, 3, 4, 5, 6, 6, 0, 2, 3, 4, 5, 6, 0,\n",
       "        3, 4, 4, 6, 1, 2, 3, 4, 5, 6, 1, 1, 3, 4, 5, 6, 0, 1, 2, 3, 3, 4, 5,\n",
       "        6, 6, 0, 1, 2, 3, 5, 6, 6, 1, 2, 2, 3, 3, 4, 5, 6, 0, 1, 2, 3, 3, 5,\n",
       "        6, 6, 0, 1, 2, 3, 6, 0, 1, 2, 2, 3, 4, 5, 6, 0, 1, 2, 3, 3, 6, 0, 1,\n",
       "        2, 3, 5, 5, 6, 6], dtype=int64),\n",
       " array([[ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  1.]]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_label = list()\n",
    "for file_name in file_list:\n",
    "\temotion_label.append(file_name[-6])\n",
    "\n",
    "emotion = list(set(emotion_label)) #  7 kind of emotion\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoded_Y = encoder.fit_transform(emotion_label)\n",
    "onehot_label = np_utils.to_categorical(encoded_Y)\n",
    "train_emotion_label = np.array(onehot_label[:int(len(file_list)*(1-TEST_PERCENTAGE))])\n",
    "test_emotion_label  = np.array(onehot_label[int(len(file_list)*(1-TEST_PERCENTAGE)):])\n",
    "\n",
    "# from keras.utils.np_utils import to_categorical\n",
    "# categorical_labels = to_categorical(int_labels, num_classes=None)\n",
    "\n",
    "encoded_Y, onehot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428, 428)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y_sr_list), len(train_emotion_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(train_y_sr_list), len(train_y_sr_list[0]), len(train_y_sr_list[0][0]), np.array(train_emotion_label).shape\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "train_y_sr_list_pad = np.array([sequence.pad_sequences(file_, maxlen=1500) for file_ in train_y_sr_list ])\n",
    "test_y_sr_list_pad = np.array([sequence.pad_sequences(file_, maxlen=1500) for file_ in test_y_sr_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((428, 10, 1500), (428, 7))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_sr_list_pad.shape, train_emotion_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_84 (Batc (None, 20, 3)             12        \n",
      "_________________________________________________________________\n",
      "lstm_96 (LSTM)               (None, 20, 256)           266240    \n",
      "_________________________________________________________________\n",
      "batch_normalization_85 (Batc (None, 20, 256)           1024      \n",
      "_________________________________________________________________\n",
      "lstm_97 (LSTM)               (None, 20, 256)           525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_86 (Batc (None, 20, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_98 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 1,321,747\n",
      "Trainable params: 1,320,205\n",
      "Non-trainable params: 1,542\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, PReLU, BatchNormalization, Flatten\n",
    "\n",
    "data_dim = 3 # <--523, fixed by padding\n",
    "timesteps = 20\n",
    "num_classes = 7\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# model2.add(LSTM(256, input_shape=(2,10), return_sequences=True))\n",
    "\n",
    "model.add(BatchNormalization(input_shape=(timesteps, data_dim)))\n",
    "\n",
    "\n",
    "model.add(LSTM(units=256, input_shape=(timesteps, data_dim), return_sequences=True))\n",
    "# (10,523) -> 1,523 : (frame1, [feature values...])\n",
    "#        -> 1,523 : (frame2, [feature values...])\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(LSTM(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "from keras import optimizers\n",
    "#Default : keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.000001, decay=1e-7, momentum=0.7, nesterov=True)\n",
    "rmsprop = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08) #This optimizer is usually a good choice for recurrent neural networks.\n",
    "\n",
    "\n",
    "\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(TimeDistributedDense(in_out_neurons))  \n",
    "# model.add(Activation(\"linear\")) \n",
    "\n",
    "\n",
    "#model.compile(optimizers.Adam(lr=1e-1), 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=rmsprop, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath='3features_rmsprop_rl0000001_relu.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 342 samples, validate on 86 samples\n",
      "Epoch 1/20\n",
      "320/342 [===========================>..] - ETA: 0s - loss: 2.3255 - acc: 0.2437Epoch 00000: val_loss improved from inf to 1.91398, saving model to 3features_rmsprop_rl0000001_relu.hdf5\n",
      "342/342 [==============================] - 10s - loss: 2.2772 - acc: 0.2544 - val_loss: 1.9140 - val_acc: 0.2674\n",
      "Epoch 2/20\n",
      "320/342 [===========================>..] - ETA: 0s - loss: 1.8291 - acc: 0.3531Epoch 00001: val_loss improved from 1.91398 to 1.88201, saving model to 3features_rmsprop_rl0000001_relu.hdf5\n",
      "342/342 [==============================] - 1s - loss: 1.8239 - acc: 0.3509 - val_loss: 1.8820 - val_acc: 0.2674\n",
      "Epoch 3/20\n",
      "320/342 [===========================>..] - ETA: 0s - loss: 1.6121 - acc: 0.4031Epoch 00002: val_loss improved from 1.88201 to 1.80909, saving model to 3features_rmsprop_rl0000001_relu.hdf5\n",
      "342/342 [==============================] - 1s - loss: 1.6592 - acc: 0.4006 - val_loss: 1.8091 - val_acc: 0.2442\n",
      "Epoch 4/20\n",
      "320/342 [===========================>..] - ETA: 0s - loss: 1.4789 - acc: 0.4281Epoch 00003: val_loss did not improve\n",
      "342/342 [==============================] - 1s - loss: 1.4738 - acc: 0.4298 - val_loss: 1.8420 - val_acc: 0.2674\n",
      "Epoch 5/20\n",
      "320/342 [===========================>..] - ETA: 0s - loss: 1.3590 - acc: 0.4562Epoch 00004: val_loss improved from 1.80909 to 1.80199, saving model to 3features_rmsprop_rl0000001_relu.hdf5\n",
      "342/342 [==============================] - 1s - loss: 1.3634 - acc: 0.4678 - val_loss: 1.8020 - val_acc: 0.2674\n",
      "Epoch 6/20\n",
      "320/342 [===========================>..] - ETA: 0s - loss: 1.4930 - acc: 0.4688Epoch 00005: val_loss improved from 1.80199 to 1.79534, saving model to 3features_rmsprop_rl0000001_relu.hdf5\n",
      "342/342 [==============================] - 1s - loss: 1.4800 - acc: 0.4737 - val_loss: 1.7953 - val_acc: 0.3140\n",
      "Epoch 7/20\n",
      "320/342 [===========================>..] - ETA: 0s - loss: 1.3422 - acc: 0.4906Epoch 00006: val_loss did not improve\n",
      "342/342 [==============================] - 1s - loss: 1.3482 - acc: 0.4971 - val_loss: 1.8229 - val_acc: 0.3488\n",
      "Epoch 8/20\n",
      "320/342 [===========================>..] - ETA: 0s - loss: 1.2499 - acc: 0.5000Epoch 00007: val_loss did not improve\n",
      "342/342 [==============================] - 1s - loss: 1.2822 - acc: 0.4825 - val_loss: 1.8169 - val_acc: 0.2209\n",
      "Epoch 9/20\n",
      "320/342 [===========================>..] - ETA: 0s - loss: 1.2600 - acc: 0.5375Epoch 00008: val_loss did not improve\n",
      "342/342 [==============================] - 1s - loss: 1.2580 - acc: 0.5322 - val_loss: 1.8103 - val_acc: 0.1977\n",
      "Epoch 10/20\n",
      "320/342 [===========================>..] - ETA: 0s - loss: 1.2539 - acc: 0.5344Epoch 00009: val_loss did not improve\n",
      "342/342 [==============================] - 1s - loss: 1.2652 - acc: 0.5263 - val_loss: 1.8529 - val_acc: 0.3488\n",
      "Epoch 11/20\n",
      "320/342 [===========================>..] - ETA: 0s - loss: 1.1455 - acc: 0.5563Epoch 00010: val_loss improved from 1.79534 to 1.74677, saving model to 3features_rmsprop_rl0000001_relu.hdf5\n",
      "342/342 [==============================] - 1s - loss: 1.1544 - acc: 0.5585 - val_loss: 1.7468 - val_acc: 0.3605\n",
      "Epoch 12/20\n",
      "320/342 [===========================>..] - ETA: 0s - loss: 1.2412 - acc: 0.5563Epoch 00011: val_loss did not improve\n",
      "342/342 [==============================] - 1s - loss: 1.2416 - acc: 0.5526 - val_loss: 1.7586 - val_acc: 0.1279\n",
      "Epoch 13/20\n",
      "320/342 [===========================>..] - ETA: 0s - loss: 1.2181 - acc: 0.5437Epoch 00012: val_loss improved from 1.74677 to 1.74616, saving model to 3features_rmsprop_rl0000001_relu.hdf5\n",
      "342/342 [==============================] - 1s - loss: 1.2156 - acc: 0.5439 - val_loss: 1.7462 - val_acc: 0.3488\n",
      "Epoch 14/20\n",
      "320/342 [===========================>..] - ETA: 0s - loss: 1.1005 - acc: 0.5875Epoch 00013: val_loss did not improve\n",
      "342/342 [==============================] - 1s - loss: 1.0913 - acc: 0.5936 - val_loss: 1.7498 - val_acc: 0.3488\n",
      "Epoch 15/20\n",
      "320/342 [===========================>..] - ETA: 0s - loss: 1.1057 - acc: 0.5469Epoch 00014: val_loss did not improve\n",
      "342/342 [==============================] - 1s - loss: 1.0863 - acc: 0.5556 - val_loss: 1.7509 - val_acc: 0.1512\n",
      "Epoch 16/20\n",
      "320/342 [===========================>..] - ETA: 0s - loss: 1.0936 - acc: 0.5563Epoch 00015: val_loss did not improve\n",
      "342/342 [==============================] - 1s - loss: 1.0958 - acc: 0.5526 - val_loss: 1.7618 - val_acc: 0.3372\n",
      "Epoch 17/20\n",
      "320/342 [===========================>..] - ETA: 0s - loss: 1.1418 - acc: 0.5938Epoch 00016: val_loss did not improve\n",
      "342/342 [==============================] - 1s - loss: 1.1393 - acc: 0.5877 - val_loss: 1.9289 - val_acc: 0.2209\n",
      "Epoch 18/20\n",
      "320/342 [===========================>..] - ETA: 0s - loss: 1.0635 - acc: 0.5719Epoch 00017: val_loss did not improve\n",
      "342/342 [==============================] - 1s - loss: 1.0701 - acc: 0.5731 - val_loss: 1.9313 - val_acc: 0.1163\n",
      "Epoch 19/20\n",
      "320/342 [===========================>..] - ETA: 0s - loss: 1.0285 - acc: 0.6156Epoch 00018: val_loss did not improve\n",
      "342/342 [==============================] - 1s - loss: 1.0557 - acc: 0.6111 - val_loss: 1.8213 - val_acc: 0.2093\n",
      "Epoch 20/20\n",
      "320/342 [===========================>..] - ETA: 0s - loss: 0.9669 - acc: 0.6219Epoch 00019: val_loss did not improve\n",
      "342/342 [==============================] - 1s - loss: 0.9810 - acc: 0.6170 - val_loss: 1.9224 - val_acc: 0.1744\n",
      "cost time : 42.96045708656311 second\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time_start = time.time()\n",
    "\n",
    "#model3.fit(train_y_sr_list_pad, train_emotion_label, epochs=50, batch_size=12, validation_split=0.2, callbacks=[checkpointer])\n",
    "model.fit(np.array(train_y_sr_list), train_emotion_label, epochs=20, batch_size=64, validation_split=0.2, callbacks=[checkpointer])\n",
    "\n",
    "\"\"\"\n",
    "Keras: why does loss decrease while val_loss increase?\n",
    "\n",
    "1. (this may be a duplicate) It looks like your model is over fitting,\n",
    "that is just memorizing the training data. In general a model that over fits can be improved by adding more dropout,\n",
    "or training and validating on a larger data set. \n",
    "Explain more about the data/features and the model for further ideas.\n",
    "\n",
    "2. You case is strange because your validation loss never got smaller. Your learning rate is suspiciously high,\n",
    "typical learning rates are about 0.001. \n",
    "\n",
    "\n",
    "3. You're overfitting. By making your model too complex, your model is finding patterns in your data that are not really there\n",
    "(these \"patterns\" are just errors/random noise). \n",
    "Your model is then using these false patterns to make predictions when really it should be ignoring them.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Audio files are sequences with different lengths.\n",
    "\n",
    "There are multiple ways to deal with variable length inputs. \n",
    "You typically feed the input, which is of fixed dimension, \n",
    "to a neural net multiple times, once for each audio frame. \n",
    "Then, the network learns from the sequence using an architecture like RNN, LSTM, \n",
    "or seq2seq (which is in flux, but in contrib/seq2seq). You can also use a simple DNN (feed-forward) architecture.\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"cost time : {} second\".format(time.time() - time_start))\n",
    "\n",
    "\n",
    "\n",
    "#currently, best result is, OptimizerRMSprop, lr= 0.01, batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "ROC: 0.75\n",
      " 96/107 [=========================>....] - ETA: 0s\n",
      "Accuracy = 0.25\n",
      "F-Score: 0.25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "import keras.utils.np_utils\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "def probas_to_classes(y_pred):\n",
    "    if len(y_pred.shape) > 1 and y_pred.shape[1] > 1:\n",
    "        return categorical_probas_to_classes(y_pred)\n",
    "    return np.array([1 if p > 0.5 else 0 for p in y_pred])\n",
    "\n",
    "def evaluate(model, inputs, outputs):\n",
    "    y_prob = model.predict_proba(inputs, verbose=0)\n",
    "    y_pred = probas_to_classes(y_prob)\n",
    "    y_true = np.argmax(outputs, 1)\n",
    "\n",
    "    roc = roc_auc_score(outputs, y_prob)\n",
    "    print (\"ROC:\",  round(roc,3))\n",
    "\n",
    "    # evaluate the model\n",
    "    score, accuracy = model.evaluate(inputs, outputs, batch_size=32)\n",
    "    print(\"\\nAccuracy = {:.2f}\".format(accuracy))\n",
    "\n",
    "    # the F-score gives a similiar value to the accuracy score, but useful for cross-checking\n",
    "    p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "    print (\"F-Score:\", round(f,2))\n",
    "    \n",
    "    return roc, accuracy\n",
    "\n",
    "\n",
    "print(\"Evaluating model...\")\n",
    "roc, acc = evaluate(model, np.array(test_y_sr_list), test_emotion_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96/107 [=========================>....] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8409418647534379, 0.25233644915518361]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(np.array(test_y_sr_list), test_emotion_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "model.save('Unit128_Drop30_1sig3relu__.h5')\n",
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
